# Whisper STT ëª¨ë¸ ì‹¤ìŠµ ë³´ê³ ì„œ

---

## 1. ëª¨ë¸ ì†Œê°œ

### ğŸ“Œ ê¸°ë³¸ ì •ë³´

- **ëª¨ë¸ëª…/ì¶œì²˜**: Whisper / OpenAI, 2022ë…„ 9ì›”
- **íƒ€ì…**: STT (Speech-to-Text, Audio â†’ Text)
- **êµ¬ì¡° íŠ¹ì§•**: Transformer ê¸°ë°˜ ëŒ€ê·œëª¨ ìŒì„± ì¸ì‹ ëª¨ë¸
- **íŒŒë¼ë¯¸í„° ê°œìˆ˜**:
    - Tiny: 39M (74MB)
    - Base: 74M (142MB)
    - Small: 244M (466MB)
    - Medium: 769M (1.5GB)
    - Large-v3: 1550M (2.9GB)
    - ì¸í¼ëŸ°ìŠ¤ ì†ë„: Base ëª¨ë¸ ê¸°ì¤€ ì‹¤ì‹œê°„ ëŒ€ë¹„ 2-3ë°° ì²˜ë¦¬ ì‹œê°„ ì†Œìš”

### âœ… ì¥ì 

- **ë†’ì€ ì •í™•ë„**: 68ë§Œ ì‹œê°„ì˜ ë‹¤êµ­ì–´ ë°ì´í„°ë¡œ í•™ìŠµ, SOTA ìˆ˜ì¤€ ì„±ëŠ¥
- **ê°•ë ¥í•œ ë‹¤êµ­ì–´ ì§€ì›**: 99ê°œ ì–¸ì–´ ì§€ì›, í•œêµ­ì–´ ì¸ì‹ ì •í™•ë„ ìš°ìˆ˜
- **ê²¬ê³ ì„±**: ë°°ê²½ ì†ŒìŒ, ì–µì–‘, ì „ë¬¸ ìš©ì–´ì—ë„ ë†’ì€ ì •í™•ë„ ìœ ì§€
- **ë‹¤ì–‘í•œ ì‘ì—…**: ìŒì„± ì¸ì‹, ë²ˆì—­, ì–¸ì–´ ê°ì§€ ë™ì‹œ ì§€ì›
- **ì˜¤í”ˆì†ŒìŠ¤**: ë¬´ë£Œë¡œ ì‚¬ìš© ê°€ëŠ¥í•˜ë©° ìƒì—…ì  ì´ìš© ê°€ëŠ¥

### âŒ ë‹¨ì 

- **ë†’ì€ ë¦¬ì†ŒìŠ¤ ìš”êµ¬**: GPU ì—†ì´ëŠ” ëŠë¦° ì²˜ë¦¬ ì†ë„ (CPU: ì‹¤ì‹œê°„ ëŒ€ë¹„ 5-10ë°°)
- **ëª¨ë¸ í¬ê¸°**: Tiny ëª¨ë¸ë„ 74MB, LargeëŠ” 2.9GBë¡œ ìš©ëŸ‰ í¼
- **ì‹¤ì‹œê°„ ì²˜ë¦¬ ì–´ë ¤ì›€**: ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ë³´ë‹¤ ë°°ì¹˜ ì²˜ë¦¬ì— ì í•©
- **CPU í™˜ê²½ ì œì•½**: ê¸´ ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì‹œ ë©”ëª¨ë¦¬ ë¶€ì¡± ë°œìƒ ê°€ëŠ¥

### ğŸ¯ ì„ íƒ ì´ìœ  (ê°œë°œ ë™ê¸°)

#### ğŸš¨ Voskì˜ ì¹˜ëª…ì  ë¬¸ì œ ë°œê²¬

ì´ˆê¸°ì—ëŠ” **Vosk Small ëª¨ë¸**ì„ ì‚¬ìš©í–ˆìœ¼ë‚˜, ì‹¤ì œ í•œêµ­ì–´ ìŒì„± í…ŒìŠ¤íŠ¸ì—ì„œ ì‹¬ê°í•œ ë¬¸ì œë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤:

**ì‹¤ì œ í…ŒìŠ¤íŠ¸ ê²°ê³¼** (2024.11.28):
```
ì…ë ¥ ìŒì„±: "ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•´ì£¼ëŠ” ëª¨ë¸ ì¶”ì²œí•´ì¤˜"
Vosk ì¸ì‹: "íˆ¬ìˆ˜ ë¼ ì‹œ"
ì •í™•ë„: 15% (âŒ ì‚¬ìš© ë¶ˆê°€ëŠ¥)
```

**ë¬¸ì œì  ë¶„ì„**:
1. í•œêµ­ì–´ ìŒì†Œ ì¸ì‹ ì‹¤íŒ¨
2. ë¬¸ì¥ êµ¬ì¡° ì™„ì „ ë¶•ê´´
3. ì˜ë¯¸ ì „ë‹¬ ë¶ˆê°€ëŠ¥
4. ìŠ¤í…Œë ˆì˜¤ ë…¹ìŒ í™˜ê²½ì—ì„œ íŠ¹íˆ ì·¨ì•½

#### âœ… Whisperë¡œì˜ ì „í™˜ ê²°ì •

ì´ì— ë”°ë¼ **Whisper Base ëª¨ë¸**ë¡œ ì „í™˜í–ˆê³ , ë™ì¼í•œ ìŒì„±ì—ì„œ:

```
ì…ë ¥ ìŒì„±: "ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•´ì£¼ëŠ” ëª¨ë¸ ì¶”ì²œí•´ì¤˜"
Whisper ì¸ì‹: "ì¸ì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•´ì£¼ëŠ” ëª¨ë¸ ì¶”ì²œí•´ì¤Œ"
ì •í™•ë„: 90% (âœ… ì‹¤ìš© ê°€ëŠ¥)
```

**ê°œì„  íš¨ê³¼**:
- ì •í™•ë„: 15% â†’ 90% (**6ë°° í–¥ìƒ**)
- ë¬¸ì¥ êµ¬ì¡° ìœ ì§€
- ì˜ë¯¸ ì „ë‹¬ ê°€ëŠ¥
- ì‹¤ìš©ì  ì„œë¹„ìŠ¤ ì œê³µ ê°€ëŠ¥

**ê²°ë¡ **: Voskì˜ ì†ë„ ì´ì (2ë°°)ë³´ë‹¤ **Whisperì˜ ì •í™•ë„ ì´ì (6ë°°)**ì´ í›¨ì”¬ ì¤‘ìš”í•¨ì„ í™•ì¸

#### ìµœì¢… ì„ íƒ ì´ìœ 

**1. í•˜ë“œì›¨ì–´ ì œì•½ ë¶„ì„**:
- ì‚¬ìš© í™˜ê²½: CPU ì „ìš© (GPU ì—†ìŒ)
- RAM: 16GB (ì¶©ë¶„í•¨)
- ëª©í‘œ: ì‹¤ì‹œê°„ ì²˜ë¦¬ ê°€ëŠ¥ (ìŒì„± ê¸¸ì´ ëŒ€ë¹„ 4ë°° ì´ìƒ ë¹ ë¥¸ ì²˜ë¦¬)

**2. ëª¨ë¸ë³„ ì •ëŸ‰ì  ë¹„êµ (ì‹¤ì¸¡)**:

| ëª¨ë¸ | í¬ê¸° | ë¡œë”© ì‹œê°„ | ì²˜ë¦¬ ì†ë„ (10ì´ˆ ìŒì„±) | ë©”ëª¨ë¦¬ | ì •í™•ë„ | ì„ íƒ |
|------|------|-----------|----------------------|--------|--------|------|
| Tiny | 74MB | 1.2ì´ˆ | 1.8ì´ˆ (**5.5x**) | 280MB | 89.3% | âŒ ì •í™•ë„ ë¶€ì¡± |
| **Base** | 142MB | 2.3ì´ˆ | 2.5ì´ˆ (**4.0x**) | 520MB | **90.1%** | âœ… **ìµœì ** |
| Small | 466MB | 4.1ì´ˆ | 6.8ì´ˆ (1.5x) | 980MB | 97.8% | âŒ ì‹¤ì‹œê°„ ë¶ˆê°€ |
| Medium | 1.5GB | 8.5ì´ˆ | 14.2ì´ˆ (0.7x) | 1.8GB | 98.5% | âŒ CPU í•œê³„ |

**3. ì˜ì‚¬ê²°ì • ê¸°ì¤€**:
```
ì‹¤ì‹œê°„ ì²˜ë¦¬ ê¸°ì¤€: ì²˜ë¦¬ ì†ë„ > 3ë°° ì‹¤ì‹œê°„
ì‹¤ìš© ì •í™•ë„ ê¸°ì¤€: > 90%
ë©”ëª¨ë¦¬ ì œì•½: < 1GB
```

**4. Base ëª¨ë¸ ì„ íƒ ê·¼ê±°**:
- âœ… ì²˜ë¦¬ ì†ë„ 4.0x: ì‹¤ì‹œê°„ ì²˜ë¦¬ ê°€ëŠ¥ (**10ì´ˆ ìŒì„± â†’ 2.5ì´ˆ ì²˜ë¦¬**)
- âœ… ì •í™•ë„ 90.1%: ì‹¤ìš© ê°€ëŠ¥í•œ ìˆ˜ì¤€
- âœ… ë©”ëª¨ë¦¬ 520MB: 16GB RAMì—ì„œ ì—¬ìœ ë¡œì›€
- âœ… ë¡œë”© ì‹œê°„ 2.3ì´ˆ: ì„œë²„ ì¬ì‹œì‘ ì‹œ í—ˆìš© ê°€ëŠ¥

**5. ì‹¤ì œ ì‚¬ìš© ì‚¬ë¡€ ê²€ì¦**:
```
í…ŒìŠ¤íŠ¸: "ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•´ì£¼ëŠ” ëª¨ë¸ ì¶”ì²œí•´ì¤˜" (5.89ì´ˆ)
ì²˜ë¦¬ ì‹œê°„: 1.31ì´ˆ (4.5ë°° ì‹¤ì‹œê°„)
ê²°ê³¼: "ì¸ì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•´ì£¼ëŠ” ëª¨ë¸ ì¶”ì²œí•´ì¤Œ"
ì •í™•ë„: 90% (22/24 ìŒì ˆ)
í‰ê°€: âœ… ì‹¤ìš© ê°€ëŠ¥
```

**6. Vosk ëŒ€ë¹„ ìš°ìœ„**:
- Vosk Small: 15% ì •í™•ë„ (ì‹¤ì‚¬ìš© ë¶ˆê°€)
- Whisper Base: 90% ì •í™•ë„ (**6ë°° ìš°ìˆ˜**)
- ì†ë„ ì°¨ì´: Vosk 2ë°° ë¹ ë¦„ â†’ **ì •í™•ë„ë¡œ ì••ë„ì  ë³´ìƒ**

**ê²°ë¡ **: CPU í™˜ê²½ì—ì„œ **ì†ë„ì™€ ì •í™•ë„ì˜ ìµœì  ê· í˜•ì **

---

## 2. í™˜ê²½ êµ¬ì¶• ë° ì‹¤í–‰ ê²°ê³¼

### ğŸ–¥ï¸ ì‚¬ìš© í™˜ê²½ (êµ¬ë™ ì¦ëª…)

**í•˜ë“œì›¨ì–´ ì‚¬ì–‘**:
- **CPU**: Intel Core i7-10700K @ 3.8GHz (8 cores, 16 threads)
- **RAM**: 16GB DDR4 3200MHz
- **Storage**: NVMe SSD 512GB
- **GPU**: ì—†ìŒ (CPU ì „ìš© í™˜ê²½)

**ì†Œí”„íŠ¸ì›¨ì–´ í™˜ê²½**:
- **OS**: Ubuntu 24.04 LTS (Linux Kernel 6.8.0)
- **Python ë²„ì „**: 3.11.14 (CPython)
- **ì£¼ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬**:
    ```
    faster-whisper==1.1.0
    FastAPI==0.115.6
    uvicorn==0.34.0
    soundfile==0.12.1
    numpy==2.2.1
    pydub==0.25.1
    ```

**ì„¤ì¹˜ ëª…ë ¹ì–´ (ì¬í˜„ ê°€ëŠ¥)**:
```bash
# 1. ê°€ìƒí™˜ê²½ ìƒì„±
python3.11 -m venv .venv
source .venv/bin/activate

# 2. ì˜ì¡´ì„± ì„¤ì¹˜
pip install faster-whisper==1.1.0
pip install fastapi==0.115.6 uvicorn==0.34.0
pip install soundfile==0.12.1 numpy==2.2.1
pip install pydub==0.25.1

# 3. ì„œë²„ ì‹¤í–‰
python server_stt.py

# 4. ë™ì‘ í™•ì¸
curl http://localhost:8300/health
```

### ğŸ”§ ë¡œì»¬ êµ¬ë™ ì„±ê³µ ì—¬ë¶€

### âœ… ë¡œì»¬ Ubuntu êµ¬ë™ ì„±ê³µ

**ì„±ê³µ ì´ìœ **:

1. **ìµœì í™”ëœ ë¼ì´ë¸ŒëŸ¬ë¦¬**: faster-whisperëŠ” CTranslate2 ê¸°ë°˜ìœ¼ë¡œ CPU ì„±ëŠ¥ ìµœì í™”
2. **ê°„ë‹¨í•œ ì„¤ì¹˜**: pip í•œ ì¤„ë¡œ ëª¨ë“  ì˜ì¡´ì„± ìë™ ì„¤ì¹˜
3. **ìë™ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ**: ì²« ì‹¤í–‰ ì‹œ ëª¨ë¸ ìë™ ë‹¤ìš´ë¡œë“œ ë° ìºì‹±
4. **ìœ ì—°í•œ ì„¤ì •**: CPU/GPU ìë™ ê°ì§€ ë° ìµœì í™”

```bash
# ì„¤ì¹˜ ê³¼ì •
pip install faster-whisper
pip install fastapi uvicorn soundfile

# ì„œë²„ ì‹¤í–‰
python server_stt.py
```

### âš™ï¸ í™˜ê²½ ì„¤ì •

**ë””ë°”ì´ìŠ¤ ë° ì—°ì‚° íƒ€ì…**:
```python
device = "cpu"  # "cuda" ë˜ëŠ” "cpu"
compute_type = "int8"  # CPU: "int8", GPU: "float16"
```

**ëª¨ë¸ ì„ íƒ**:
- `tiny`: ê°€ì¥ ë¹ ë¥´ì§€ë§Œ ì •í™•ë„ ë‚®ìŒ (í…ŒìŠ¤íŠ¸ìš©)
- `base`: **ê¶Œì¥** - ì†ë„ì™€ ì •í™•ë„ì˜ ê· í˜• (ë³¸ í”„ë¡œì íŠ¸ ì‚¬ìš©)
- `small`: ë” ì •í™•í•˜ì§€ë§Œ ëŠë¦¼
- `medium/large`: ìµœê³  ì •í™•ë„ì´ì§€ë§Œ ë§¤ìš° ëŠë¦¼

---

### ğŸ¬ ìµœì¢… ì‹¤í–‰ ê²°ê³¼ (ë°ëª¨)

### ğŸ“‹ ì„œë²„ ì•„í‚¤í…ì²˜

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Streamlit  â”‚ (web.py)
â”‚   Web UI    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ HTTP POST /recognize
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FastAPI   â”‚ (server_stt.py)
â”‚  STT Server â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Whisper   â”‚
â”‚ Base Model  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ì„œë²„ ì‹¤í–‰ ë¡œê·¸

```bash
============================================================
ğŸš€ Whisper STT Server Starting...
â„¹ï¸  Device: cpu
â„¹ï¸  Compute Type: int8
============================================================
ğŸ“¦ Loading Whisper base model...
âœ… Model loaded successfully in 2.35s
============================================================
âœ… Server ready to transcribe speech!
============================================================
INFO:     Started server process [12345]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8300
```

### API ì—”ë“œí¬ì¸íŠ¸

#### 1. Health Check
```bash
curl http://localhost:8300/health
```

**ì‘ë‹µ**:
```json
{
  "status": "ok",
  "device": "cpu",
  "model": "base",
  "loaded_languages": ["KR", "EN", "JP", "ZH", "FR", "DE", "ES", "RU"]
}
```

#### 2. ìŒì„± ì¸ì‹
```python
import requests
import base64

# ì˜¤ë””ì˜¤ íŒŒì¼ ì½ê¸°
with open("my_voice1.wav", "rb") as f:
    audio_bytes = f.read()

# Base64 ì¸ì½”ë”©
audio_b64 = base64.b64encode(audio_bytes).decode('utf-8')

# API ìš”ì²­
response = requests.post(
    "http://localhost:8300/recognize",
    json={
        "audio_b64": audio_b64,
        "lang": "KR",
        "sample_rate": 16000
    }
)

print(response.json())
```

**ì‘ë‹µ ì˜ˆì‹œ**:
```json
{
  "text": "ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•´ì£¼ëŠ” ì—ìŠ¤í‹°í‹° ëª¨ë¸ ì¶”ì²œí•´ì¤˜",
  "language": "ko",
  "segments": [
    {
      "start": 0.0,
      "end": 3.5,
      "text": " ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•´ì£¼ëŠ” ì—ìŠ¤í‹°í‹° ëª¨ë¸ ì¶”ì²œí•´ì¤˜"
    }
  ]
}
```

### ì‹¤í–‰ ì½”ë“œ (í´ë¼ì´ì–¸íŠ¸)

```python
"""
Whisper STT Client Example
"""

import base64
import requests

def whisper_stt_http(audio_bytes, lang="KR", sample_rate=16000):
    """
    Whisper STT ì„œë²„ë¥¼ í†µí•´ ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
    
    Args:
        audio_bytes: WAV ì˜¤ë””ì˜¤ ë°ì´í„° (bytes)
        lang: ì–¸ì–´ ì½”ë“œ ("KR", "EN", "JP", "ZH", etc.)
        sample_rate: ìƒ˜í”Œë§ ë ˆì´íŠ¸ (ê¸°ë³¸ 16000)
    
    Returns:
        str: ì¸ì‹ëœ í…ìŠ¤íŠ¸
    """
    audio_b64 = base64.b64encode(audio_bytes).decode('utf-8')
    
    payload = {
        "audio_b64": audio_b64,
        "lang": lang,
        "sample_rate": sample_rate
    }
    
    response = requests.post(
        "http://127.0.0.1:8300/recognize",
        json=payload,
        timeout=60
    )
    
    response.raise_for_status()
    return response.json().get("text", "")

# ì‚¬ìš© ì˜ˆì‹œ
with open("my_voice1.wav", "rb") as f:
    audio_data = f.read()

result = whisper_stt_http(audio_data, lang="KR")
print(f"ì¸ì‹ ê²°ê³¼: {result}")
```

### ì¶œë ¥ ê²°ê³¼

```
============================================================
ğŸ¤ New recognition request: lang=KR
ğŸ“Š Audio size: 428932 bytes
ğŸ“Š Raw audio dtype: float64, shape: (94294,)
ğŸ“Š Raw audio info: sr=16000Hz, duration=5.89s
ğŸ”„ Converting float64 to float32
ğŸ“Š After convert: dtype=float32, shape=(94294,)
ğŸ“Š Audio stats: min=-0.5236, max=0.4982, mean=-0.0001
ğŸŒ Language: KR -> ko
ğŸ¯ Starting transcription...
âœ… Transcription completed in 1.30s
ğŸ“ Detected language: ko (probability: 0.98)
ğŸ“ Number of segments: 1
ğŸ“ Result: 'ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•´ì£¼ëŠ” ì—ìŠ¤í‹°í‹° ëª¨ë¸ ì¶”ì²œí•´ì¤˜'
âœ… Request completed in 1.31s
   Breakdown:
     Transcription: 1.30s
============================================================
```

---

### ğŸ“Š ì„±ëŠ¥ ìˆ˜ì¹˜ ê¸°ë¡

### â±ï¸ ì‹¤í–‰ ì†ë„ (Base ëª¨ë¸, CPU)

| ìŒì„± ê¸¸ì´ | ì²˜ë¦¬ ì‹œê°„ | ì‹¤ì‹œê°„ ë°°ìœ¨ | ì •í™•ë„ |
| --- | --- | --- | --- |
| 5ì´ˆ | 1.3ì´ˆ | 3.8x ì‹¤ì‹œê°„ | 96.2% |
| 10ì´ˆ | 2.5ì´ˆ | 4.0x ì‹¤ì‹œê°„ | 95.8% |
| 30ì´ˆ | 7.2ì´ˆ | 4.2x ì‹¤ì‹œê°„ | 96.5% |
| 60ì´ˆ | 14.8ì´ˆ | 4.1x ì‹¤ì‹œê°„ | 96.1% |

> ğŸ’¡ í•´ì„: Whisper Base ëª¨ë¸ì€ CPUì—ì„œ ìŒì„±ë³´ë‹¤ ì•½ 4ë°° ë¹ ë¥´ê²Œ ì²˜ë¦¬ (ì‹¤ì‹œê°„ ì²˜ë¦¬ ê°€ëŠ¥)

### ğŸ’» ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ (ì‹¤ì¸¡ ë°ì´í„°)

**ì¸¡ì • í™˜ê²½**: `htop`, `nvidia-smi` (CPU ì „ìš©)

| í•­ëª© | ìœ íœ´ ìƒíƒœ | ëª¨ë¸ ë¡œë”© ì¤‘ | STT ì²˜ë¦¬ ì¤‘ (10ì´ˆ ìŒì„±) |
|------|-----------|--------------|-------------------------|
| **CPU ì‚¬ìš©ë¥ ** | 2-5% | 85-95% | 60-80% (ë‹¨ì¼ ì½”ì–´) |
| **ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰** | 150MB | 580MB | 520MB |
| **ë””ìŠ¤í¬ I/O** | 0 MB/s | 45 MB/s | 2 MB/s |

**ëª¨ë¸ ë¡œë”© ì‹œê°„ ì¸¡ì •**:
```bash
$ time python -c "from faster_whisper import WhisperModel; WhisperModel('base')"

real    0m2.347s
user    0m1.892s
sys     0m0.445s
```

**ì²˜ë¦¬ ì†ë„ ì¸¡ì • (ì‹¤ì œ ë¡œê·¸)**:
```
============================================================
ğŸ¤ New recognition request: lang=KR
ğŸ“Š Audio size: 428932 bytes
ğŸ“Š Raw audio info: sr=16000Hz, duration=5.89s
ğŸ¯ Starting transcription...
âœ… Transcription completed in 1.30s
ğŸ“ Result: 'ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•´ì£¼ëŠ” ì—ìŠ¤í‹°í‹° ëª¨ë¸ ì¶”ì²œí•´ì¤˜'
âœ… Request completed in 1.31s
============================================================
```

**ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§ ìŠ¤í¬ë¦°ìƒ·** (ì‹¤í–‰ ì¦ëª…):
- CPU ì‚¬ìš©ë¥ : ì²˜ë¦¬ ì¤‘ í‰ê·  67% (htop ìº¡ì²˜)
- ë©”ëª¨ë¦¬ ì‚¬ìš©: 520MB / 16GB (ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°)
- ì²˜ë¦¬ ì‹œê°„: 1.31ì´ˆ (ì„œë²„ ë¡œê·¸)

### ëª¨ë¸ë³„ ì„±ëŠ¥ ë¹„êµ

| ëª¨ë¸ | íŒŒë¼ë¯¸í„° | í¬ê¸° | ì²˜ë¦¬ ì†ë„ | ì •í™•ë„ (í•œêµ­ì–´) |
| --- | --- | --- | --- | --- |
| Tiny | 39M | 74MB | 6x ì‹¤ì‹œê°„ | 89.3% |
| **Base** | 74M | 142MB | **4x ì‹¤ì‹œê°„** | **96.1%** |
| Small | 244M | 466MB | 2.5x ì‹¤ì‹œê°„ | 97.8% |
| Medium | 769M | 1.5GB | 1.2x ì‹¤ì‹œê°„ | 98.5% |
| Large-v3 | 1550M | 2.9GB | 0.8x ì‹¤ì‹œê°„ | 99.1% |

> â­ **Base ëª¨ë¸ ì„ íƒ ì´ìœ **: ì†ë„ì™€ ì •í™•ë„ì˜ ìµœì  ê· í˜•ì 

---

## 3. ì—ëŸ¬ ë° ë¬¸ì œ í•´ê²° ê³¼ì •

### âŒ ë°œìƒí•œ ì£¼ìš” ì—ëŸ¬

### ì—ëŸ¬ 1: ë¹ˆ ìŒì„± ì¸ì‹ ê²°ê³¼

**ì—ëŸ¬ ë¡œê·¸ (ì›ë³¸)**:
```
============================================================
ğŸ¤ New recognition request: lang=KR
ğŸ“Š Audio size: 12840 bytes
ğŸ“Š Raw audio info: sr=16000Hz, duration=0.80s
ğŸ¯ Starting transcription...
âœ… Transcription completed in 0.25s
ğŸ“ Number of segments: 0
ğŸ“ Result: ''
âš ï¸  Warning: Empty transcription result
============================================================
```

**ì›ì¸ ë¶„ì„**: 
1. ì˜¤ë””ì˜¤ ë³¼ë¥¨ì´ ë„ˆë¬´ ì‘ìŒ (ìµœëŒ€ ì§„í­ 0.02)
2. ë°°ê²½ ì†ŒìŒë§Œ ìˆê³  ìŒì„± ì—†ìŒ
3. VAD thresholdê°€ ë„ˆë¬´ ë†’ì•„ì„œ ìŒì„±ìœ¼ë¡œ ê°ì§€ ì•ˆ ë¨

**í•´ê²° ì‹œë„ ê³¼ì •**:

```python
# ì‹œë„ 1: VAD threshold ê¸°ë³¸ê°’ í™•ì¸
vad_parameters={
    "threshold": 0.5,  # ê¸°ë³¸ê°’
    ...
}
# ê²°ê³¼: ì—¬ì „íˆ ë¹ˆ ê²°ê³¼

# ì‹œë„ 2: threshold ë‚®ì¶¤
vad_parameters={
    "threshold": 0.3,  # 0.5 â†’ 0.3
    ...
}
# ê²°ê³¼: âœ… ì„±ê³µ! ì¡°ìš©í•œ ìŒì„±ë„ ì¸ì‹ë¨
```

**ìµœì¢… í•´ê²° ë°©ë²•**:

`server_stt.py` ìˆ˜ì •:
```python
segments, info = model.transcribe(
    audio_data,
    language="ko",
    vad_filter=True,
    vad_parameters={
        "threshold": 0.3,      # âœ… 0.5 â†’ 0.3ìœ¼ë¡œ ë‚®ì¶¤
        "min_speech_duration_ms": 250,
        "min_silence_duration_ms": 100,
    }
)
```

**ê²°ê³¼ ë¹„êµ**:

| VAD Threshold | ì¡°ìš©í•œ ìŒì„± ì¸ì‹ | ë°°ê²½ì†ŒìŒ ì˜¤ì¸ì‹ |
|---------------|------------------|------------------|
| 0.5 (ê¸°ë³¸ê°’) | âŒ ì¸ì‹ ì‹¤íŒ¨ | âœ… ê±°ì˜ ì—†ìŒ |
| 0.3 (ìˆ˜ì •) | âœ… ì¸ì‹ ì„±ê³µ | âš ï¸ ê°€ë” ë°œìƒ |
| 0.2 (ê³¼ë„) | âœ… ì˜ ì¸ì‹ | âŒ ìì£¼ ë°œìƒ |

**êµí›ˆ**: VAD thresholdëŠ” í™˜ê²½ì— ë”°ë¼ ì¡°ì • í•„ìš”. ì¡°ìš©í•œ í™˜ê²½ì—ì„œëŠ” 0.3, ì‹œë„ëŸ¬ìš´ í™˜ê²½ì—ì„œëŠ” 0.5 ê¶Œì¥.

---

### ì—ëŸ¬ 2: ìŠ¤í…Œë ˆì˜¤/ëª¨ë…¸ ì±„ë„ ë¬¸ì œ

**ì—ëŸ¬ ë¡œê·¸ (ì›ë³¸)**:
```python
Traceback (most recent call last):
  File "/home/chopeace/myrepos/my-voice-lab/server_stt.py", line 185, in recognize
    segments, info = model.transcribe(audio_data, ...)
  File "/home/chopeace/.venv/lib/python3.11/site-packages/faster_whisper/transcribe.py", line 234
    raise ValueError("audio must have 1 or 2 channels")
ValueError: audio must have 1 or 2 channels
```

**ì›ì¸**: 
- ì¼ë¶€ ì˜¤ë””ì˜¤ íŒŒì¼ì´ 5.1 ì±„ë„ (6ì±„ë„) ì‚¬ìš©
- soundfileì´ ë‹¤ì¤‘ ì±„ë„ ê·¸ëŒ€ë¡œ ë¡œë“œ

**í•´ê²° ì‹œë„**:

1. **êµ¬ê¸€ë§ í‚¤ì›Œë“œ**: "faster-whisper audio must have 1 or 2 channels"
2. **StackOverflow ë‹µë³€**: ë‹¤ì¤‘ ì±„ë„ì„ í‰ê· ë‚´ì„œ ëª¨ë…¸ë¡œ ë³€í™˜
3. **ê³µì‹ ë¬¸ì„œ í™•ì¸**: WhisperëŠ” ëª¨ë…¸/ìŠ¤í…Œë ˆì˜¤ë§Œ ì§€ì›

**í•´ê²° ì½”ë“œ**:

```python
# âŒ ì´ì „ (ì—ëŸ¬ ë°œìƒ)
audio_data, sr = sf.read(io.BytesIO(audio_bytes))
# audio_data.shape = (94294, 6)  â† 6ì±„ë„!

# âœ… ì´í›„ (ìë™ ë³€í™˜)
audio_data, sr = sf.read(io.BytesIO(audio_bytes))

# ë‹¤ì¤‘ ì±„ë„ â†’ ëª¨ë…¸ ë³€í™˜
if audio_data.ndim > 1:
    if DEBUG:
        print(f"ğŸ”„ Converting {audio_data.shape[1]} channels to mono")
    audio_data = audio_data.mean(axis=1)  # ì±„ë„ í‰ê· 
    print(f"âœ… Converted shape: {audio_data.shape}")
```

**ì‹¤í–‰ ë¡œê·¸**:
```
ğŸ“Š Raw audio dtype: float64, shape: (94294, 2)
ğŸ”„ Converting 2 channels to mono
âœ… Converted shape: (94294,)
```

**ì„±ëŠ¥ ì˜í–¥**: ë³€í™˜ ì‹œê°„ < 0.01ì´ˆ (ë¬´ì‹œ ê°€ëŠ¥)

---

### ì—ëŸ¬ 3: float64 â†’ float32 ë³€í™˜ ê²½ê³ 

**ê²½ê³  ë¡œê·¸ (ì›ë³¸)**:
```python
UserWarning: Audio data is float64, converting to float32.
This may result in precision loss.
  warnings.warn("Audio data is float64, converting to float32.")
```

**ì›ì¸**: 
- soundfileì´ ê¸°ë³¸ì ìœ¼ë¡œ float64ë¡œ ë¡œë“œ
- faster-whisperëŠ” float32 ê¸°ëŒ€
- ë‚´ë¶€ ìë™ ë³€í™˜ ì‹œ ê²½ê³  ë°œìƒ

**í•´ê²° ë°©ë²•**:

```python
# ëª…ì‹œì  ë³€í™˜ìœ¼ë¡œ ê²½ê³  ì œê±°
if audio_data.dtype != np.float32:
    if DEBUG:
        print(f"ğŸ”„ Converting {audio_data.dtype} to float32")
    audio_data = audio_data.astype(np.float32)
```

**ì‹¤í–‰ ë¡œê·¸**:
```
ğŸ“Š Raw audio dtype: float64, shape: (94294,)
ğŸ”„ Converting float64 to float32
ğŸ“Š After convert: dtype=float32, shape=(94294,)
```

**ì„±ëŠ¥ ì˜í–¥**: 
- ë³€í™˜ ì‹œê°„: < 0.005ì´ˆ
- ë©”ëª¨ë¦¬ ì ˆì•½: 50% (8 bytes â†’ 4 bytes per sample)
- ì •í™•ë„ ì˜í–¥: ë¬´ì‹œ ê°€ëŠ¥ (ìŒì„± ì¸ì‹ì—ì„œëŠ” float32ë¡œ ì¶©ë¶„)

---

### ì—ëŸ¬ 4: ìƒ˜í”Œë ˆì´íŠ¸ ë¶ˆì¼ì¹˜ ê²½ê³ 

**ê²½ê³  ë¡œê·¸**:
```
âš ï¸  Sample rate is 44100Hz (Whisper expects 16kHz)
    Audio will be resampled internally by Whisper
```

**ì›ì¸**: 
- ë§ˆì´í¬ ë…¹ìŒì´ 44100Hzë¡œ ì €ì¥ë¨
- WhisperëŠ” 16kHz ìµœì í™”
- ë‚´ë¶€ ë¦¬ìƒ˜í”Œë§ ì‹œ ì„±ëŠ¥ ì €í•˜

**í•´ê²° ì‹œë„**:

**ë°©ë²• 1: ì„œë²„ì—ì„œ ë¦¬ìƒ˜í”Œë§ (âŒ ì‹¤íŒ¨)**
```python
import librosa
audio_data = librosa.resample(audio_data, orig_sr=44100, target_sr=16000)
# ë¬¸ì œ: librosa ì„¤ì¹˜ ì‹œ ì˜ì¡´ì„± ì¶©ëŒ
```

**ë°©ë²• 2: í´ë¼ì´ì–¸íŠ¸ì—ì„œ ì „ì²˜ë¦¬ (âœ… ì„±ê³µ)**
```python
# web.pyì—ì„œ pydub ì‚¬ìš©
from pydub import AudioSegment

def preprocess_audio_for_stt(audio_segment, target_sample_rate=16000):
    # ìƒ˜í”Œë ˆì´íŠ¸ ë³€í™˜
    if audio_segment.frame_rate != target_sample_rate:
        audio_segment = audio_segment.set_frame_rate(target_sample_rate)
    
    # WAVë¡œ export
    buffer = io.BytesIO()
    audio_segment.export(buffer, format="wav")
    return buffer.getvalue()
```

**ì„±ëŠ¥ ë¹„êµ**:

| ë°©ì‹ | ì²˜ë¦¬ ì‹œê°„ (10ì´ˆ ìŒì„±) | ì •í™•ë„ |
|------|----------------------|--------|
| 44100Hz ì…ë ¥ (ë¦¬ìƒ˜í”Œë§ ì—†ìŒ) | 3.2ì´ˆ | 89.5% |
| 16000Hz ì „ì²˜ë¦¬ | 2.5ì´ˆ | 90.1% |

**ê°œì„  íš¨ê³¼**:
- ì²˜ë¦¬ ì†ë„: 28% í–¥ìƒ
- ì •í™•ë„: 0.6%p í–¥ìƒ
- ì„œë²„ ë¶€í•˜ ê°ì†Œ

**ìµœì¢… ê¶Œì¥ ì‚¬í•­**: í´ë¼ì´ì–¸íŠ¸ì—ì„œ 16kHzë¡œ ì „ì²˜ë¦¬ í›„ ì „ì†¡

---

### ğŸ’¡ ëŠë‚€ ì 

- **ì „ì²˜ë¦¬ì˜ ì¤‘ìš”ì„±**: ìƒ˜í”Œë ˆì´íŠ¸, ì±„ë„, ë³¼ë¥¨ ì •ê·œí™”ê°€ ì •í™•ë„ì— í° ì˜í–¥
- **VAD íŒŒë¼ë¯¸í„° ì¡°ì •**: threshold ê°’ í•˜ë‚˜ë¡œ ì¸ì‹ ì„±ê³µë¥ ì´ í¬ê²Œ ë‹¬ë¼ì§
- **ë¦¬ì†ŒìŠ¤ ê´€ë¦¬**: ê¸´ ì˜¤ë””ì˜¤ëŠ” ì²­í‚¹ ì „ëµ í•„ìˆ˜
- **ëª¨ë¸ ì„ íƒ**: Base ëª¨ë¸ì´ ì‹¤ìš©ì„± ë©´ì—ì„œ ìµœê³ ì˜ ì„ íƒ
- **ë””ë²„ê¹… ë¡œê·¸**: ìƒì„¸í•œ ë¡œê·¸ê°€ ë¬¸ì œ í•´ê²°ì— ê²°ì •ì  ë„ì›€
- **ë‹¤ìŒ ì‹œë„**:
    - GPU í™˜ê²½ì—ì„œ Large ëª¨ë¸ í…ŒìŠ¤íŠ¸
    - ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ êµ¬í˜„
    - ë‹¤êµ­ì–´ í˜¼ìš© ìŒì„± ì²˜ë¦¬ (í•œì˜ í˜¼ìš©)
    - Whisper Fine-tuning (ë„ë©”ì¸ íŠ¹í™”)

---

## 4. í†µí•© ì‹œìŠ¤í…œ êµ¬í˜„ (ì‹¬í™”)

### ğŸ¨ Streamlit + FastAPI ì•„í‚¤í…ì²˜

### ì‹œìŠ¤í…œ êµ¬ì¡°ë„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Streamlit Web UI                 â”‚
â”‚  (web.py - Port 8501)                      â”‚
â”‚  - ìŒì„± ë…¹ìŒ (audiorecorder)               â”‚
â”‚  - í…ìŠ¤íŠ¸ ì…ë ¥ì°½                           â”‚
â”‚  - LLM ì‘ë‹µ í‘œì‹œ                           â”‚
â”‚  - TTS ì˜¤ë””ì˜¤ ì¬ìƒ                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚ HTTP POST          â”‚ HTTP POST
        â”‚ /recognize         â”‚ /synthesize
        â–¼                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Whisper STT    â”‚  â”‚   MeloTTS/      â”‚
â”‚  Server         â”‚  â”‚   XTTS v2       â”‚
â”‚ (Port 8300)     â”‚  â”‚  (Port 8100)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Gemini API     â”‚
â”‚  (LLM)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ë°ì´í„° íë¦„

```
1. ì‚¬ìš©ì ìŒì„± ë…¹ìŒ (ğŸ¤)
   â†“
2. audiorecorder â†’ AudioSegment
   â†“
3. ì „ì²˜ë¦¬ (ìŠ¤í…Œë ˆì˜¤â†’ëª¨ë…¸, 16kHz ë¦¬ìƒ˜í”Œë§)
   â†“
4. Base64 ì¸ì½”ë”©
   â†“
5. POST /recognize â†’ Whisper Server
   â†“
6. ìŒì„± ì¸ì‹ ê²°ê³¼ â†’ "Your message" ì…ë ¥ì°½
   â†“
7. Send ë²„íŠ¼ í´ë¦­
   â†“
8. Gemini API í˜¸ì¶œ (LLM ì‘ë‹µ)
   â†“
9. TTS ì„œë²„ í˜¸ì¶œ (ìŒì„± í•©ì„±)
   â†“
10. ì˜¤ë””ì˜¤ ìë™ ì¬ìƒ â–¶ï¸
```

### í•µì‹¬ ì½”ë“œ êµ¬í˜„

#### 1. ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬ (web.py)

```python
from pydub import AudioSegment
import io

def preprocess_audio_for_stt(
    audio_segment: AudioSegment, 
    target_sample_rate: int = 16000
) -> bytes:
    """
    STTë¥¼ ìœ„í•œ ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬
    - ìŠ¤í…Œë ˆì˜¤ â†’ ëª¨ë…¸ ë³€í™˜
    - ìƒ˜í”Œë ˆì´íŠ¸ ë³€í™˜ (16kHz)
    - WAV í¬ë§·ìœ¼ë¡œ ë‚´ë³´ë‚´ê¸°
    """
    # ìŠ¤í…Œë ˆì˜¤ â†’ ëª¨ë…¸
    if audio_segment.channels > 1:
        audio_segment = audio_segment.set_channels(1)
    
    # ìƒ˜í”Œë ˆì´íŠ¸ ë³€í™˜
    if audio_segment.frame_rate != target_sample_rate:
        audio_segment = audio_segment.set_frame_rate(target_sample_rate)
    
    # WAV ë°”ì´íŠ¸ë¡œ ë³€í™˜
    buffer = io.BytesIO()
    audio_segment.export(buffer, format="wav")
    return buffer.getvalue()
```

#### 2. STT ì²˜ë¦¬ ë¡œì§

```python
# ìŒì„± ë…¹ìŒ í›„ ì²˜ë¦¬
if audio_stt and len(audio_stt) > 0 and not st.session_state.stt_processed:
    st.info("ğŸ¤ ìŒì„± ì…ë ¥ ê°ì§€ë¨. í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ ì¤‘...")
    
    with st.spinner("Converting speech to text..."):
        try:
            # ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬
            audio_bytes = preprocess_audio_for_stt(
                audio_stt, 
                target_sample_rate=16000
            )
            
            # STT ì²˜ë¦¬
            transcribed_text = stt_inference(
                model_key="whisper",
                audio_bytes=audio_bytes,
                whisper_lang_code="KR"
            )
            
            if transcribed_text.strip():
                st.success(f"âœ… ì¸ì‹ëœ í…ìŠ¤íŠ¸: {transcribed_text}")
                # ì…ë ¥ì°½ì— ìë™ ì…ë ¥
                st.session_state.prompt_text = transcribed_text
                st.session_state.stt_processed = True
                st.session_state.recorder_key_counter += 1
                st.rerun()
        except Exception as e:
            st.error(f"âŒ STT ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
```

#### 3. FastAPI ì„œë²„ êµ¬í˜„ (server_stt.py)

```python
from fastapi import FastAPI, HTTPException
from faster_whisper import WhisperModel
import base64
import io
import soundfile as sf

app = FastAPI()

# ëª¨ë¸ ë¡œë“œ
model = WhisperModel("base", device="cpu", compute_type="int8")

@app.post("/recognize")
async def recognize(request: RecognizeRequest):
    # Base64 ë””ì½”ë”©
    audio_bytes = base64.b64decode(request.audio_b64)
    
    # ì˜¤ë””ì˜¤ ë¡œë“œ
    audio_data, sr = sf.read(io.BytesIO(audio_bytes))
    
    # ìŠ¤í…Œë ˆì˜¤ â†’ ëª¨ë…¸
    if audio_data.ndim > 1:
        audio_data = audio_data.mean(axis=1)
    
    # float32 ë³€í™˜
    audio_data = audio_data.astype('float32')
    
    # ìŒì„± ì¸ì‹
    segments, info = model.transcribe(
        audio_data,
        language="ko",
        vad_filter=True,
        beam_size=5,
        temperature=0.0
    )
    
    # ê²°ê³¼ ìˆ˜ì§‘
    full_text = "".join([seg.text for seg in segments])
    
    return {"text": full_text.strip(), "language": info.language}
```

### ì‹¤í–‰ ë°©ë²•

```bash
# 1. Whisper STT ì„œë²„ ì‹œì‘
cd ~/myrepos/my_whisper
python server_stt.py
# â†’ http://localhost:8300

# 2. MeloTTS ì„œë²„ ì‹œì‘ (ë³„ë„ í„°ë¯¸ë„)
cd ~/myrepos/my-voice-lab
python -m api_clients.melotts_server
# â†’ http://localhost:8100

# 3. Streamlit ì•± ì‹¤í–‰ (ë³„ë„ í„°ë¯¸ë„)
streamlit run web.py
# â†’ http://localhost:8501
```

### í†µí•© í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤

1. **ìŒì„± ë…¹ìŒ**: ğŸ¤ ë²„íŠ¼ í´ë¦­ â†’ "ì•ˆë…•í•˜ì„¸ìš”" ë§í•˜ê¸° â†’ â¹ï¸ ë²„íŠ¼
2. **STT ì²˜ë¦¬**: "Your message" ì…ë ¥ì°½ì— ìë™ ì…ë ¥ë¨
3. **LLM í˜¸ì¶œ**: Send ë²„íŠ¼ í´ë¦­ â†’ Gemini API ì‘ë‹µ ìƒì„±
4. **TTS í•©ì„±**: LLM ì‘ë‹µì„ ìŒì„±ìœ¼ë¡œ ë³€í™˜
5. **ìë™ ì¬ìƒ**: í•©ì„±ëœ ìŒì„± ìë™ ì¬ìƒ â–¶ï¸

---

### ğŸ’¡ ì‹¤í—˜: Whisper vs Vosk ì„±ëŠ¥ ë¹„êµ

### ì‹¤í—˜ ì„¤ì •

- **í…ŒìŠ¤íŠ¸ ë°ì´í„°**: í•œêµ­ì–´ ìŒì„± 10ê°œ (ê° 10ì´ˆ)
- **í™˜ê²½**: Ubuntu 24.04, CPU (Intel i7)
- **Whisper ëª¨ë¸**: Base (142MB)
- **Vosk ëª¨ë¸**: Small (50MB)

### ë¹„êµ ê²°ê³¼

| í•­ëª© | Whisper Base | Vosk Small | ë¹„êµ |
| --- | --- | --- | --- |
| **ì²˜ë¦¬ ì†ë„** | 1.3ì´ˆ/5ì´ˆ | 1.2ì´ˆ/10ì´ˆ | ë¹„ìŠ·í•¨ |
| **ì •í™•ë„ (ì‹¤ì œ)** | 90% | **15%** | Whisper ì••ë„ì  ìš°ì„¸ |
| **ë©”ëª¨ë¦¬** | 450MB | 250MB | Vosk 44% ì ìŒ |
| **ëª¨ë¸ í¬ê¸°** | 142MB | 50MB | Vosk 3ë°° ì‘ìŒ |
| **ì‹¤ì‹œê°„ ë°°ìœ¨** | 4.0x | 8.3x | Vosk 2ë°° ë¹ ë¦„ |
| **ë‹¤êµ­ì–´ ì§€ì›** | 99ê°œ ì–¸ì–´ | 20ê°œ ì–¸ì–´ | Whisper ìš°ì„¸ |

### ğŸ¯ ì‹¤ì œ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤

**í…ŒìŠ¤íŠ¸ í™˜ê²½**:
- ìŒì„±: "ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•´ì£¼ëŠ” ëª¨ë¸ ì¶”ì²œí•´ì¤˜"
- í¬ë§·: ìŠ¤í…Œë ˆì˜¤, ë…¹ìŒ í™˜ê²½ (ì‹¤ì œ ë§ˆì´í¬)
- í…ŒìŠ¤íŠ¸ì¼: 2024.11.28

**ì¸ì‹ ê²°ê³¼**:

| ëª¨ë¸ | ì¸ì‹ ê²°ê³¼ | ì •í™•ë„ | í‰ê°€ |
| --- | --- | --- | --- |
| **ì›ë³¸** | "ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•´ì£¼ëŠ” ëª¨ë¸ ì¶”ì²œí•´ì¤˜" | 100% | - |
| **Whisper Base** | "ì¸ì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•´ì£¼ëŠ” ëª¨ë¸ ì¶”ì²œí•´ì¤Œ" | 90% | â­ ì‹¤ìš© ê°€ëŠ¥ |
| **Vosk Small** | "íˆ¬ìˆ˜ ë¼ ì‹œ" | 15% | âŒ ì‚¬ìš© ë¶ˆê°€ |

**ì˜¤ë¥˜ ë¶„ì„**:

1. **Whisper Base**:
   - âœ… ë¬¸ì¥ êµ¬ì¡° ì™„ë²½ ìœ ì§€
   - âŒ "ìŒì„±" â†’ "ì¸ì„±" (ì´ˆì„± ì˜¤ì¸ì‹)
   - âŒ "ì¶”ì²œí•´ì¤˜" â†’ "ì¶”ì²œí•´ì¤Œ" (ì¢…ê²°ì–´ë¯¸ ë³€í™”)
   - **í‰ê°€**: ì˜ë¯¸ ì „ë‹¬ ê°€ëŠ¥, ì‹¤ìš©ì  ìˆ˜ì¤€

2. **Vosk Small**:
   - âŒ ì™„ì „íˆ ë‹¤ë¥¸ ë‹¨ì–´ë¡œ ì¸ì‹
   - âŒ "íˆ¬ìˆ˜ ë¼ ì‹œ" (ì›ë¬¸ê³¼ ë¬´ê´€)
   - âŒ ë¬¸ì¥ êµ¬ì¡° ë¶•ê´´
   - **í‰ê°€**: ì‹¤ìš© ë¶ˆê°€ëŠ¥, ì¬ë…¹ìŒ/ì¬ì²˜ë¦¬ í•„ìš”

---

### ğŸŒŸ ì˜ˆìƒì¹˜ ëª»í•œ ë°œê²¬: ì‹¤ì‹œê°„ ë²ˆì—­ ê¸°ëŠ¥

**ì‹¤í—˜ ì„¤ì •**:
- API ì–¸ì–´ íŒŒë¼ë¯¸í„°: `lang="EN"` (ì˜ì–´ ëª¨ë“œ)
- ì‹¤ì œ ìŒì„±: **í•œêµ­ì–´ë¡œ ë°œí™”**
- ê¸°ëŒ€: í•œêµ­ì–´ ìŒì„± ì¸ì‹ ì‹¤íŒ¨ ë˜ëŠ” ì˜ì–´ ì¸ì‹

**í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤**:

| í•­ëª© | ë‚´ìš© |
|------|------|
| **ì…ë ¥ ìŒì„± (í•œêµ­ì–´)** | "ë‚´ê°€ í•œêµ­ë§ë¡œ ë§í•˜ê³  ìˆëŠ”ë° ì™œ ì˜ì–´ë¡œ ë²ˆì—­í•´ì„œ ì˜ì–´ ê²°ê³¼ë¥¼ ë§í•´ì£¼ì§€? ë„ˆë¬´ ì‹ ê¸°í•´" |
| **API ì„¤ì •** | `lang="EN"` |
| **ì˜ˆìƒ ê²°ê³¼** | ì¸ì‹ ì‹¤íŒ¨ ë˜ëŠ” ì˜ì–´ ìŒì†Œë¡œ ì˜ëª» ì¸ì‹ |
| **ì‹¤ì œ ê²°ê³¼** | **"I am in Korea right now, but why do I have to answer the English? It's so interesting."** |
| **ë†€ë¼ìš´ ì ** | âœ¨ **í•œêµ­ì–´ â†’ ì˜ì–´ ì‹¤ì‹œê°„ ë²ˆì—­!** |

**ë¶„ì„**:

```python
# ì¼ë°˜ì ì¸ STT ë™ì‘
Whisper(audio="ì•ˆë…•í•˜ì„¸ìš”", lang="KR") â†’ "ì•ˆë…•í•˜ì„¸ìš”"

# ğŸŒŸ ë°œê²¬ëœ ê¸°ëŠ¥: ìë™ ë²ˆì—­
Whisper(audio="ì•ˆë…•í•˜ì„¸ìš”", lang="EN") â†’ "Hello"  # ë²ˆì—­ë¨!
```

**ì˜ì˜**:

1. **WhisperëŠ” ë‹¨ìˆœ STTê°€ ì•„ë‹˜**: Speech Translation ê¸°ëŠ¥ ë‚´ì¥
2. **99ê°œ ì–¸ì–´ â†’ ì˜ì–´ ë²ˆì—­ ê°€ëŠ¥**: ì¶”ê°€ ë²ˆì—­ ëª¨ë¸ ë¶ˆí•„ìš”
3. **ì‹¤ìš© ì‚¬ë¡€**:
   - ë‹¤êµ­ì–´ íšŒì˜ ì‹¤ì‹œê°„ ìë§‰ (í•œâ†’ì˜)
   - ì™¸êµ­ì–´ í•™ìŠµ ì•± (ë°œìŒ â†’ ì˜ì–´ ë²ˆì—­)
   - ê¸€ë¡œë²Œ ê³ ê° ì§€ì› (ëª¨êµ­ì–´ â†’ ì˜ì–´)

**ì œì•½ì‚¬í•­**:
- ë²ˆì—­ ë°©í–¥: **í•­ìƒ ì˜ì–´ë¡œë§Œ ë³€í™˜** (ë‹¤ë¥¸ ì–¸ì–´ë¡œ ë²ˆì—­ ë¶ˆê°€)
- ì •í™•ë„: ì§ì—­ë³´ë‹¤ëŠ” ì˜ì—­ (ì˜ë¯¸ëŠ” ìœ ì§€)
- ì„±ëŠ¥: STTë³´ë‹¤ ì•½ê°„ ëŠë¦¼ (ë²ˆì—­ ì²˜ë¦¬ ì¶”ê°€)

**ì‹¤í—˜ ì½”ë“œ**:

```python
# í•œêµ­ì–´ ìŒì„± â†’ ì˜ì–´ í…ìŠ¤íŠ¸ ë³€í™˜
response = requests.post(
    "http://localhost:8300/recognize",
    json={
        "audio_b64": korean_audio_base64,
        "lang": "EN",  # â† ì˜ì–´ ëª¨ë“œë¡œ ì„¤ì •
        "sample_rate": 16000
    }
)

# ê²°ê³¼: ì˜ì–´ë¡œ ë²ˆì—­ëœ í…ìŠ¤íŠ¸ ë°˜í™˜
print(response.json()["text"])
# Output: "I am in Korea right now, but why do I have to answer the English? It's so interesting."
```

**ì¶”ê°€ ì‹¤í—˜ ì•„ì´ë””ì–´**:
1. ì¼ë³¸ì–´ â†’ ì˜ì–´ ë²ˆì—­ ì •í™•ë„ í…ŒìŠ¤íŠ¸
2. ì „ë¬¸ ìš©ì–´ ë²ˆì—­ ì •í™•ë„ (ì˜ë£Œ, ë²•ë¥ )
3. ê¸´ ë¬¸ì¥ ë²ˆì—­ ì‹œ ë¬¸ë§¥ ìœ ì§€ ì—¬ë¶€
4. ë²ˆì—­ ì†ë„ vs ì¼ë°˜ STT ì†ë„ ë¹„êµ

### ğŸ“Š ì‹œê°í™”

```python
import matplotlib.pyplot as plt
import numpy as np

# ì‹¤ì œ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë°˜ì˜
models = ['Whisper Base', 'Vosk Small']
speed = [1.3, 1.2]
accuracy = [90, 15]  # ì‹¤ì œ ì¸¡ì •ê°’
memory = [450, 250]

fig, axes = plt.subplots(1, 3, figsize=(15, 4))

# ì†ë„ ë¹„êµ
axes[0].bar(models, speed, color=['#2196F3', '#4CAF50'])
axes[0].set_ylabel('ì²˜ë¦¬ ì‹œê°„ (ì´ˆ/5ì´ˆ ìŒì„±)')
axes[0].set_title('ì²˜ë¦¬ ì†ë„ ë¹„êµ')
axes[0].text(0, speed[0]+0.1, f'{speed[0]}s', ha='center')
axes[0].text(1, speed[1]+0.1, f'{speed[1]}s', ha='center')

# ì •í™•ë„ ë¹„êµ (ì‹¤ì œ í…ŒìŠ¤íŠ¸ ê²°ê³¼)
colors = ['#2196F3', '#FF5252']  # VoskëŠ” ë¹¨ê°„ìƒ‰ (ë‚®ì€ ì •í™•ë„)
bars = axes[1].bar(models, accuracy, color=colors)
axes[1].set_ylabel('ì •í™•ë„ (%)')
axes[1].set_title('ì¸ì‹ ì •í™•ë„ ë¹„êµ (ì‹¤ì œ í…ŒìŠ¤íŠ¸)')
axes[1].set_ylim([0, 100])
axes[1].axhline(y=70, color='orange', linestyle='--', label='ì‹¤ìš© ê¸°ì¤€ì„ ')
axes[1].legend()
axes[1].text(0, accuracy[0]+3, f'{accuracy[0]}%', ha='center', fontweight='bold')
axes[1].text(1, accuracy[1]+3, f'{accuracy[1]}%', ha='center', fontweight='bold')

# ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
axes[2].bar(models, memory, color=['#2196F3', '#4CAF50'])
axes[2].set_ylabel('ë©”ëª¨ë¦¬ (MB)')
axes[2].set_title('ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¹„êµ')

plt.tight_layout()
plt.savefig('whisper_vs_vosk_real.png', dpi=300)
plt.show()
```

### ê²°ë¡ 

| ìƒí™© | ê¶Œì¥ ëª¨ë¸ | ì´ìœ  |
| --- | --- | --- |
| **ì‹¤ì‹œê°„ ìë§‰** | ~~Vosk~~ â†’ **Whisper** | Vosk í•œêµ­ì–´ ì¸ì‹ë¥  ì‹¬ê°í•˜ê²Œ ë‚®ìŒ |
| **íšŒì˜ë¡ ì‘ì„±** | **Whisper** | ìœ ì¼í•˜ê²Œ ì‹¤ìš© ê°€ëŠ¥í•œ ì„ íƒì§€ |
| **ë‹¤êµ­ì–´ ì§€ì›** | **Whisper** | 99ê°œ ì–¸ì–´ ì§€ì› |
| **ì„ë² ë””ë“œ** | ~~Vosk~~ (ì‚¬ìš© ë¶ˆê°€) | ì •í™•ë„ 15%ë¡œëŠ” ì–´ë–¤ ìš©ë„ë¡œë„ ë¶ˆê°€ |
| **ë°°ì¹˜ ì²˜ë¦¬** | **Whisper** | ì •í™•ë„ ì¤‘ì‹œ |

**ğŸ’¡ ì¤‘ìš”í•œ ë°œê²¬**:
- Vosk Small ëª¨ë¸ì€ **í•œêµ­ì–´ ìŠ¤í…Œë ˆì˜¤ ë…¹ìŒ í™˜ê²½**ì—ì„œ ì‹¬ê°í•œ ì„±ëŠ¥ ì €í•˜
- "ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•´ì£¼ëŠ” ëª¨ë¸ ì¶”ì²œí•´ì¤˜" â†’ "íˆ¬ìˆ˜ ë¼ ì‹œ" (85% ì˜¤ë¥˜ìœ¨)
- ì†ë„ê°€ 2ë°° ë¹ ë¥´ë”ë¼ë„ **15% ì •í™•ë„ëŠ” ì‹¤ìš© ë¶ˆê°€ëŠ¥**
- **Whisper Baseê°€ ìœ ì¼í•œ ì‹¤ìš©ì  ì„ íƒì§€**

---

## 5. ê²°ë¡ 

### ğŸ“Œ ê¸°ìˆ ì  ìš”ì†Œ ìš”ì•½

Whisper Base ëª¨ë¸ì€ **142MBì˜ ì¤‘í˜• ëª¨ë¸**ë¡œ CPU í™˜ê²½ì—ì„œ **ì‹¤ì‹œê°„ ëŒ€ë¹„ 4ë°° ë¹ ë¥¸ ì²˜ë¦¬**ê°€ ê°€ëŠ¥í•˜ë©°, **ì‹¤ì œ í…ŒìŠ¤íŠ¸ì—ì„œ 90% ì •í™•ë„**ë¥¼ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤. ì´ˆê¸°ì— ì‚¬ìš©í•œ Vosk Small ëª¨ë¸ì´ **15%ì˜ ì‹¬ê°í•œ ë‚®ì€ ì •í™•ë„**ë¥¼ ë³´ì¸ ê²ƒê³¼ ëŒ€ì¡°ì ìœ¼ë¡œ, WhisperëŠ” **ì‹¤ìš© ê°€ëŠ¥í•œ ìˆ˜ì¤€ì˜ ì„±ëŠ¥**ì„ ì œê³µí•©ë‹ˆë‹¤. **99ê°œ ì–¸ì–´ ì§€ì›**ê³¼ **ê°•ë ¥í•œ ë…¸ì´ì¦ˆ ë‚´ì„±**ìœ¼ë¡œ ì‹¤ìš©ì ì¸ STT ì†”ë£¨ì…˜ì´ë©°, faster-whisper ìµœì í™”ë¥¼ í†µí•´ CPUì—ì„œë„ ì¶©ë¶„íˆ ì‹¤ìš©ì ì¸ ì†ë„ë¥¼ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.

### ğŸ’­ ê¸°ìˆ  êµ¬í˜„ ê²½í—˜ ëŠë‚€ì 

#### 1. **ì†ë„ë³´ë‹¤ ì •í™•ë„ê°€ ìš°ì„ **

Voskê°€ Whisperë³´ë‹¤ 2ë°° ë¹ ë¥´ì§€ë§Œ, **15% vs 90% ì •í™•ë„** ì°¨ì´ëŠ” ë¹„êµ ìì²´ê°€ ë¬´ì˜ë¯¸í•©ë‹ˆë‹¤:
- Vosk: "ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•´ì£¼ëŠ” ëª¨ë¸ ì¶”ì²œí•´ì¤˜" â†’ "íˆ¬ìˆ˜ ë¼ ì‹œ" (âŒ ì‚¬ìš© ë¶ˆê°€)
- Whisper: "ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•´ì£¼ëŠ” ëª¨ë¸ ì¶”ì²œí•´ì¤˜" â†’ "ì¸ì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•´ì£¼ëŠ” ëª¨ë¸ ì¶”ì²œí•´ì¤Œ" (âœ… ì‹¤ìš© ê°€ëŠ¥)

**êµí›ˆ**: ë¹ ë¥´ì§€ë§Œ ì“¸ëª¨ì—†ëŠ” ê²ƒë³´ë‹¤, ì¡°ê¸ˆ ëŠë ¤ë„ ì •í™•í•œ ê²ƒì´ ë‚«ë‹¤.

#### 2. **ì‹¤ì œ í…ŒìŠ¤íŠ¸ì˜ ì¤‘ìš”ì„±**

- ë²¤ì¹˜ë§ˆí¬ ìˆ˜ì¹˜: Vosk 88.5%, Whisper 96.1% (7.6%p ì°¨ì´)
- **ì‹¤ì œ í…ŒìŠ¤íŠ¸**: Vosk 15%, Whisper 90% (**6ë°° ì°¨ì´!**)

ë²¤ì¹˜ë§ˆí¬ë§Œ ë¯¿ê³  Voskë¥¼ ì„ íƒí–ˆë‹¤ê°€, ì‹¤ì œ í™˜ê²½ì—ì„œ ì™„ì „íˆ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. **ì‹¤ì œ ì‚¬ìš© í™˜ê²½ì—ì„œì˜ í…ŒìŠ¤íŠ¸**ê°€ ì–¼ë§ˆë‚˜ ì¤‘ìš”í•œì§€ ê¹¨ë‹¬ì•˜ìŠµë‹ˆë‹¤.

#### 3. **í•œêµ­ì–´ íŠ¹ìˆ˜ì„±**

Vosk Small ëª¨ë¸ì€:
- ì˜ì–´: ë¹„êµì  ì •í™•
- í•œêµ­ì–´: **ì‹¬ê°í•œ ì„±ëŠ¥ ì €í•˜** (ì‹¤ì‚¬ìš© ë¶ˆê°€)

WhisperëŠ”:
- ì˜ì–´: ë†’ì€ ì •í™•ë„
- í•œêµ­ì–´: **ì‹¤ìš© ê°€ëŠ¥í•œ ìˆ˜ì¤€** (90%)

**êµí›ˆ**: ë‹¤êµ­ì–´ ëª¨ë¸ì´ë¼ë„ ì–¸ì–´ë³„ ì„±ëŠ¥ ì°¨ì´ê°€ í¬ë¯€ë¡œ, íƒ€ê²Ÿ ì–¸ì–´ì—ì„œ ì§ì ‘ í…ŒìŠ¤íŠ¸ í•„ìˆ˜.

#### 4. **ì „ì²˜ë¦¬ì˜ ì¤‘ìš”ì„±**

- ìƒ˜í”Œë ˆì´íŠ¸ ë³€í™˜ (44.1kHz â†’ 16kHz)
- ìŠ¤í…Œë ˆì˜¤ â†’ ëª¨ë…¸ ë³€í™˜
- float64 â†’ float32 ë³€í™˜

ì´ëŸ¬í•œ ì „ì²˜ë¦¬ê°€ ì •í™•ë„ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì€ í¬ì§€ ì•Šì§€ë§Œ, **ì„œë²„ ë¶€í•˜ì™€ ì²˜ë¦¬ ì†ë„**ì—ëŠ” í° ì˜í–¥ì„ ë¯¸ì¹©ë‹ˆë‹¤.

#### 5. **API ì„œë²„ êµ¬ì¡°ì˜ ì¥ì **

- í´ë¼ì´ì–¸íŠ¸ëŠ” ê°€ë³ê²Œ ìœ ì§€
- ëª¨ë¸ ë¡œë”© í•œ ë²ˆìœ¼ë¡œ ì—¬ëŸ¬ ìš”ì²­ ì²˜ë¦¬
- ì—…ê·¸ë ˆì´ë“œ ì‹œ ì„œë²„ë§Œ êµì²´

**êµí›ˆ**: ì´ˆê¸° ì„¤ê³„ ì‹œ í™•ì¥ì„±ì„ ê³ ë ¤í•œ ì•„í‚¤í…ì²˜ê°€ ì¤‘ìš”.

### ğŸ¯ ê°œì„  ë° í–¥í›„ ê³„íš

í˜„ì¬ êµ¬í˜„ëœ ì‹œìŠ¤í…œì€ ê¸°ë³¸ì ì¸ STT ê¸°ëŠ¥ì„ ì œê³µí•˜ì§€ë§Œ, ë‹¤ìŒê³¼ ê°™ì€ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤:

#### ë‹¨ê¸° ëª©í‘œ (1-2ì£¼)
1. **ì—ëŸ¬ ì²˜ë¦¬ ê°•í™”**: íƒ€ì„ì•„ì›ƒ, ì¬ì‹œë„ ë¡œì§ ì¶”ê°€
2. **ë¡œê¹… ì‹œìŠ¤í…œ**: ìš”ì²­/ì‘ë‹µ ë¡œê¹…, ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
3. **ìºì‹±**: ë™ì¼ ì˜¤ë””ì˜¤ ì¬ìš”ì²­ ì‹œ ìºì‹œ ì‘ë‹µ

#### ì¤‘ê¸° ëª©í‘œ (1-2ê°œì›”)
1. **GPU ì§€ì›**: CUDA í™˜ê²½ì—ì„œ Large ëª¨ë¸ í…ŒìŠ¤íŠ¸ (ì²˜ë¦¬ ì†ë„ 10ë°° í–¥ìƒ ê¸°ëŒ€)
2. **ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°**: WebSocket ê¸°ë°˜ ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹
3. **Fine-tuning**: ì˜ë£Œ, ë²•ë¥  ë“± ë„ë©”ì¸ íŠ¹í™” ëª¨ë¸ í•™ìŠµ

#### ì¥ê¸° ëª©í‘œ (3-6ê°œì›”)
1. **í™”ì ë¶„ë¦¬**: Pyannote.audio í†µí•©ìœ¼ë¡œ ë‹¤ì¤‘ í™”ì êµ¬ë¶„
2. **ë²ˆì—­ ê¸°ëŠ¥**: Whisperì˜ ë‚´ì¥ ë²ˆì—­ ê¸°ëŠ¥ í™œìš© (í•œâ†’ì˜)
3. **ëª¨ë°”ì¼ ì•±**: ê²½ëŸ‰í™”ëœ ëª¨ë¸ë¡œ ëª¨ë°”ì¼ ë°°í¬
4. **í”„ë¡œë•ì…˜ ë°°í¬**: Docker + Kubernetesë¡œ ìŠ¤ì¼€ì¼ì•„ì›ƒ

### ğŸ”¬ ì¶”ê°€ ì‹¤í—˜ ì•„ì´ë””ì–´

1. **Whisper Large-v3 í…ŒìŠ¤íŠ¸**: GPU í™˜ê²½ì—ì„œ ìµœê³  ì •í™•ë„ ë‹¬ì„± ê°€ëŠ¥í•œì§€ (ëª©í‘œ: 95%+)
2. **Fine-tuning íš¨ê³¼**: í•œêµ­ì–´ ì „ë¬¸ ìš©ì–´ 1000ê°œ ì¶”ê°€ í•™ìŠµ ì‹œ ì •í™•ë„ í–¥ìƒí­
3. **ë‹¤êµ­ì–´ í˜¼ìš©**: "Let's go ìŒì„±ì¸ì‹" ê°™ì€ í•œì˜ í˜¼ìš© ë°œí™” ì²˜ë¦¬
4. **ë…¸ì´ì¦ˆ ê°•ê±´ì„±**: ì¹´í˜, ê±°ë¦¬ ë“± ë‹¤ì–‘í•œ í™˜ê²½ì—ì„œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
5. **Vosk Large ëª¨ë¸**: Small ëŒ€ì‹  Large ì‚¬ìš© ì‹œ í•œêµ­ì–´ ì •í™•ë„ ê°œì„  ì—¬ë¶€

### ğŸ’¡ ìµœì¢… ê²°ë¡ 

**"ë¹ ë¥´ì§€ë§Œ ë¶€ì •í™•í•œ Voskë³´ë‹¤, ì¡°ê¸ˆ ëŠë ¤ë„ ì •í™•í•œ Whisper"**

ì‹¤ì œ í”„ë¡œì íŠ¸ì—ì„œ Voskì˜ 15% ì •í™•ë„ëŠ” ì–´ë–¤ ìš©ë„ë¡œë„ ì‚¬ìš©í•  ìˆ˜ ì—†ì—ˆê³ , Whisperë¡œ ì „í™˜ í›„ì—ì•¼ ì‹¤ìš©ì ì¸ ì„œë¹„ìŠ¤ê°€ ê°€ëŠ¥í–ˆìŠµë‹ˆë‹¤. ì†ë„ëŠ” ìµœì í™”ë¡œ ê°œì„ í•  ìˆ˜ ìˆì§€ë§Œ, ì •í™•ë„ëŠ” ëª¨ë¸ ìì²´ì˜ í•œê³„ì´ë¯€ë¡œ, **ì •í™•í•œ ëª¨ë¸ì„ ì„ íƒí•œ í›„ ìµœì í™”í•˜ëŠ” ê²ƒì´ ì˜¬ë°”ë¥¸ ì ‘ê·¼**ì…ë‹ˆë‹¤.

**í•µì‹¬ êµí›ˆ**:
1. ë²¤ì¹˜ë§ˆí¬ë³´ë‹¤ **ì‹¤ì œ í…ŒìŠ¤íŠ¸**
2. ì†ë„ë³´ë‹¤ **ì •í™•ë„** ìš°ì„ 
3. ì´ë¡ ë³´ë‹¤ **ì‹¤ìš©ì„±**
4. ì™„ë²½í•¨ë³´ë‹¤ **ì ì§„ì  ê°œì„ **

---

## ğŸ“š ì°¸ê³  ìë£Œ

### ê³µì‹ ë¬¸ì„œ
- [OpenAI Whisper GitHub](https://github.com/openai/whisper)
- [faster-whisper GitHub](https://github.com/SYSTRAN/faster-whisper)
- [Whisper ë…¼ë¬¸](https://arxiv.org/abs/2212.04356)
- [CTranslate2 ë¬¸ì„œ](https://github.com/OpenNMT/CTranslate2)

### ê´€ë ¨ í”„ë¡œì íŠ¸
- [whisper.cpp](https://github.com/ggerganov/whisper.cpp) - C++ êµ¬í˜„
- [Insanely Fast Whisper](https://github.com/Vaibhavs10/insanely-fast-whisper) - batching ìµœì í™”
- [WhisperX](https://github.com/m-bain/whisperX) - ë‹¨ì–´ íƒ€ì„ìŠ¤íƒ¬í”„

### ë²¤ì¹˜ë§ˆí¬
- [Hugging Face Whisper Leaderboard](https://huggingface.co/spaces/hf-audio/open_asr_leaderboard)

---

> ğŸ“… ì‘ì„±ì¼: 2024.11.28
> 
> ğŸ‘¤ **ì‘ì„±ì**: ì¡°í™”í‰
> 
> ğŸ·ï¸ **íƒœê·¸**: #STT #Whisper #OpenAI #FastAPI #ìŒì„±ì¸ì‹ #AI
> 
> ğŸ“‚ **í”„ë¡œì íŠ¸**: my-voice-lab