# Whisper STT Server

> ğŸ¤ Fast and accurate Speech-to-Text using faster-whisper

OpenAIì˜ Whisper ëª¨ë¸ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ ê³ ì„±ëŠ¥ ìŒì„± ì¸ì‹ ì„œë²„ì…ë‹ˆë‹¤. faster-whisperë¥¼ ì‚¬ìš©í•˜ì—¬ CPU í™˜ê²½ì—ì„œë„ ì‹¤ìš©ì ì¸ ì†ë„ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

---

## ğŸ“‹ ëª©ì°¨

- [íŠ¹ì§•](#íŠ¹ì§•)
- [ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­](#ì‹œìŠ¤í…œ-ìš”êµ¬ì‚¬í•­)
- [ì„¤ì¹˜](#ì„¤ì¹˜)
- [ì‚¬ìš©ë²•](#ì‚¬ìš©ë²•)
- [API ë¬¸ì„œ](#api-ë¬¸ì„œ)
- [ì„±ëŠ¥](#ì„±ëŠ¥)
- [ë¬¸ì œ í•´ê²°](#ë¬¸ì œ-í•´ê²°)
- [ë¼ì´ì„¼ìŠ¤](#ë¼ì´ì„¼ìŠ¤)

---

## âœ¨ íŠ¹ì§•

- **ë†’ì€ ì •í™•ë„**: OpenAI Whisper ëª¨ë¸ ê¸°ë°˜ (í•œêµ­ì–´ 90%+ ì •í™•ë„)
- **ë¹ ë¥¸ ì²˜ë¦¬**: faster-whisper ìµœì í™”ë¡œ ì‹¤ì‹œê°„ ëŒ€ë¹„ 4ë°° ë¹ ë¥¸ ì²˜ë¦¬
- **ë‹¤êµ­ì–´ ì§€ì›**: 99ê°œ ì–¸ì–´ ì¦‰ì‹œ ì‚¬ìš© ê°€ëŠ¥ (ì¶”ê°€ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë¶ˆí•„ìš”)
- **CPU ìµœì í™”**: GPU ì—†ì´ë„ ì‹¤ìš©ì ì¸ ì†ë„
- **RESTful API**: FastAPI ê¸°ë°˜ í‘œì¤€ HTTP API
- **ìë™ ì „ì²˜ë¦¬**: ìŠ¤í…Œë ˆì˜¤â†’ëª¨ë…¸, ìƒ˜í”Œë ˆì´íŠ¸ ë³€í™˜ ìë™ ì²˜ë¦¬
- **VAD ë‚´ì¥**: Voice Activity Detectionìœ¼ë¡œ ì •í™•ë„ í–¥ìƒ

---

## ğŸ’» ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­

### ìµœì†Œ ì‚¬ì–‘
- **OS**: Ubuntu 20.04+ / Windows 10+ / macOS 10.15+
- **Python**: 3.8 - 3.11
- **RAM**: 1GB (Base ëª¨ë¸ ê¸°ì¤€)
- **ë””ìŠ¤í¬**: 500MB (ëª¨ë¸ ìºì‹œ í¬í•¨)

### ê¶Œì¥ ì‚¬ì–‘
- **RAM**: 2GB+
- **CPU**: 4 ì½”ì–´ ì´ìƒ
- **ë””ìŠ¤í¬**: 1GB (ì—¬ëŸ¬ ëª¨ë¸ ì‚¬ìš© ì‹œ)

### GPU ì‚¬ìš© ì‹œ (ì„ íƒ)
- **CUDA**: 11.2+
- **GPU RAM**: 2GB+ (Base ëª¨ë¸)

---

## ğŸš€ ì„¤ì¹˜

### 1. ì €ì¥ì†Œ í´ë¡ 

```bash
git clone https://github.com/yourusername/my-whisper.git
cd my-whisper
```

### 2. ê°€ìƒí™˜ê²½ ìƒì„± (ê¶Œì¥)

```bash
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
# .venv\Scripts\activate  # Windows
```

### 3. ì˜ì¡´ì„± ì„¤ì¹˜

```bash
pip install -r requirements.txt
```

ë˜ëŠ” ìˆ˜ë™ ì„¤ì¹˜:

```bash
pip install faster-whisper fastapi uvicorn soundfile numpy
```

### 4. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (ìë™)

ì²« ì‹¤í–‰ ì‹œ ëª¨ë¸ì´ ìë™ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œë©ë‹ˆë‹¤. ìˆ˜ë™ ë‹¤ìš´ë¡œë“œëŠ” ë¶ˆí•„ìš”í•©ë‹ˆë‹¤.

---

## ğŸ¯ ì‚¬ìš©ë²•

### ê¸°ë³¸ ì‹¤í–‰

```bash
python server_stt.py
```

ì„œë²„ê°€ `http://localhost:8300`ì—ì„œ ì‹œì‘ë©ë‹ˆë‹¤.

### ë¡œê·¸ ë ˆë²¨ ì¡°ì •

`server_stt.py` íŒŒì¼ ìƒë‹¨ì—ì„œ ì„¤ì •:

```python
VERBOSE = True   # Falseë¡œ ì„¤ì •í•˜ë©´ ìµœì†Œ ë¡œê·¸ë§Œ
DEBUG = True     # Falseë¡œ ì„¤ì •í•˜ë©´ ìƒì„¸ ì •ë³´ ìˆ¨ê¹€
```

### ëª¨ë¸ ë³€ê²½

`server_stt.py`ì—ì„œ ëª¨ë¸ í¬ê¸° ë³€ê²½:

```python
# tiny: ê°€ì¥ ë¹ ë¦„, ë‚®ì€ ì •í™•ë„
# base: ê¶Œì¥ (ê¸°ë³¸ê°’)
# small: ë” ì •í™•, ëŠë¦¼
# medium/large: ìµœê³  ì •í™•ë„, ë§¤ìš° ëŠë¦¼

model = WhisperModel("base", device=device, compute_type=compute_type)
```

### GPU ì‚¬ìš©

```python
device = "cuda"  # CPU â†’ CUDAë¡œ ë³€ê²½
compute_type = "float16"  # int8 â†’ float16ìœ¼ë¡œ ë³€ê²½
```

---

## ğŸ“¡ API ë¬¸ì„œ

### 1. Health Check

ì„œë²„ ìƒíƒœë¥¼ í™•ì¸í•©ë‹ˆë‹¤.

**Endpoint**: `GET /health`

**ì‘ë‹µ ì˜ˆì‹œ**:
```json
{
  "status": "ok",
  "device": "cpu",
  "model": "base",
  "loaded_languages": ["KR", "EN", "JP", "ZH", "FR", "DE", "ES", "RU"]
}
```

**cURL ì˜ˆì‹œ**:
```bash
curl http://localhost:8300/health
```

---

### 2. ìŒì„± ì¸ì‹

ì˜¤ë””ì˜¤ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

**Endpoint**: `POST /recognize`

**ìš”ì²­ ë³¸ë¬¸**:
```json
{
  "audio_b64": "UklGRiQAAABXQVZFZm10IBAAAAABAAEA...",
  "lang": "KR",
  "sample_rate": 16000
}
```

**íŒŒë¼ë¯¸í„°**:
| í•„ë“œ | íƒ€ì… | í•„ìˆ˜ | ì„¤ëª… |
|------|------|------|------|
| `audio_b64` | string | âœ… | Base64 ì¸ì½”ë”©ëœ WAV ì˜¤ë””ì˜¤ |
| `lang` | string | âœ… | ì–¸ì–´ ì½”ë“œ (KR, EN, JP, ZH, FR, DE, ES, RU) |
| `sample_rate` | integer | âŒ | ìƒ˜í”Œë§ ë ˆì´íŠ¸ (ê¸°ë³¸ê°’: 16000) |

**ì‘ë‹µ ì˜ˆì‹œ**:
```json
{
  "text": "ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•´ì£¼ëŠ” ëª¨ë¸ ì¶”ì²œí•´ì¤˜",
  "language": "ko",
  "segments": [
    {
      "start": 0.0,
      "end": 3.5,
      "text": " ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•´ì£¼ëŠ” ëª¨ë¸ ì¶”ì²œí•´ì¤˜"
    }
  ]
}
```

**Python ì˜ˆì‹œ**:
```python
import requests
import base64

# ì˜¤ë””ì˜¤ íŒŒì¼ ì½ê¸°
with open("audio.wav", "rb") as f:
    audio_bytes = f.read()

# Base64 ì¸ì½”ë”©
audio_b64 = base64.b64encode(audio_bytes).decode('utf-8')

# API ìš”ì²­
response = requests.post(
    "http://localhost:8300/recognize",
    json={
        "audio_b64": audio_b64,
        "lang": "KR",
        "sample_rate": 16000
    },
    timeout=60
)

result = response.json()
print(f"ì¸ì‹ëœ í…ìŠ¤íŠ¸: {result['text']}")
```

**cURL ì˜ˆì‹œ**:
```bash
# audio.wavë¥¼ Base64ë¡œ ì¸ì½”ë”©
AUDIO_B64=$(base64 -w 0 audio.wav)

# API í˜¸ì¶œ
curl -X POST http://localhost:8300/recognize \
  -H "Content-Type: application/json" \
  -d "{
    \"audio_b64\": \"$AUDIO_B64\",
    \"lang\": \"KR\",
    \"sample_rate\": 16000
  }"
```

---

## ğŸ“Š ì„±ëŠ¥

### ì²˜ë¦¬ ì†ë„ (Base ëª¨ë¸, CPU)

| ìŒì„± ê¸¸ì´ | ì²˜ë¦¬ ì‹œê°„ | ì‹¤ì‹œê°„ ë°°ìœ¨ |
|-----------|-----------|-------------|
| 5ì´ˆ | 1.3ì´ˆ | 3.8x |
| 10ì´ˆ | 2.5ì´ˆ | 4.0x |
| 30ì´ˆ | 7.2ì´ˆ | 4.2x |
| 60ì´ˆ | 14.8ì´ˆ | 4.1x |

### ëª¨ë¸ë³„ ë¹„êµ

| ëª¨ë¸ | íŒŒë¼ë¯¸í„° | í¬ê¸° | ì²˜ë¦¬ ì†ë„ | ì •í™•ë„ (í•œêµ­ì–´) |
|------|----------|------|-----------|-----------------|
| Tiny | 39M | 74MB | 6x ì‹¤ì‹œê°„ | 89.3% |
| **Base** | 74M | 142MB | **4x ì‹¤ì‹œê°„** | **90%+** |
| Small | 244M | 466MB | 2.5x ì‹¤ì‹œê°„ | 97.8% |
| Medium | 769M | 1.5GB | 1.2x ì‹¤ì‹œê°„ | 98.5% |
| Large-v3 | 1550M | 2.9GB | 0.8x ì‹¤ì‹œê°„ | 99.1% |

> ğŸ’¡ **ê¶Œì¥**: Base ëª¨ë¸ì´ ì†ë„ì™€ ì •í™•ë„ì˜ ìµœì  ê· í˜•ì 

### ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰

- **ëª¨ë¸ ë¡œë”© ì‹œê°„**: 2.35ì´ˆ (Base ëª¨ë¸)
- **ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰**: 400-600MB
- **CPU ì‚¬ìš©ëŸ‰**: 60-80% (ë‹¨ì¼ ì½”ì–´)

---

## ğŸŒ ì§€ì› ì–¸ì–´

WhisperëŠ” **99ê°œ ì–¸ì–´**ë¥¼ ì§€ì›í•©ë‹ˆë‹¤. ì£¼ìš” ì–¸ì–´ ì½”ë“œ:

| ì–¸ì–´ | ì½”ë“œ | ì •í™•ë„ |
|------|------|--------|
| í•œêµ­ì–´ | KR | 90%+ |
| ì˜ì–´ | EN | 95%+ |
| ì¼ë³¸ì–´ | JP | 93%+ |
| ì¤‘êµ­ì–´ | ZH | 94%+ |
| í”„ë‘ìŠ¤ì–´ | FR | 92%+ |
| ë…ì¼ì–´ | DE | 91%+ |
| ìŠ¤í˜ì¸ì–´ | ES | 93%+ |
| ëŸ¬ì‹œì•„ì–´ | RU | 90%+ |

ì „ì²´ ëª©ë¡: [Whisper ê³µì‹ ë¬¸ì„œ](https://github.com/openai/whisper#available-models-and-languages)

---

## ğŸ”§ ì„¤ì •

### 1. í¬íŠ¸ ë³€ê²½

`server_stt.py` ë§ˆì§€ë§‰ ì¤„:

```python
uvicorn.run(app, host="0.0.0.0", port=8300)  # ì›í•˜ëŠ” í¬íŠ¸ë¡œ ë³€ê²½
```

### 2. VAD íŒŒë¼ë¯¸í„° ì¡°ì •

`server_stt.py`ì˜ `transcribe` í•¨ìˆ˜:

```python
segments, info = model.transcribe(
    audio_data,
    language=whisper_lang,
    vad_filter=True,
    vad_parameters={
        "threshold": 0.5,      # 0.3-0.7 (ë‚®ì„ìˆ˜ë¡ ë¯¼ê°)
        "min_speech_duration_ms": 250,  # ìµœì†Œ ìŒì„± ê¸¸ì´
        "min_silence_duration_ms": 100,  # ìµœì†Œ ë¬´ìŒ ê¸¸ì´
    }
)
```

### 3. Beam Search ì¡°ì •

```python
segments, info = model.transcribe(
    audio_data,
    beam_size=5,  # 1-10 (ë†’ì„ìˆ˜ë¡ ì •í™•í•˜ì§€ë§Œ ëŠë¦¼)
    best_of=5,    # beam_sizeì™€ ë™ì¼í•˜ê²Œ ì„¤ì • ê¶Œì¥
    temperature=0.0,  # 0.0 = ê²°ì •ì , >0 = í™•ë¥ ì 
)
```

---

## ğŸ› ë¬¸ì œ í•´ê²°

### 1. ì„œë²„ê°€ ì‹œì‘ë˜ì§€ ì•ŠìŒ

**ì¦ìƒ**:
```
ModuleNotFoundError: No module named 'faster_whisper'
```

**í•´ê²°**:
```bash
pip install faster-whisper --upgrade
```

---

### 2. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨

**ì¦ìƒ**:
```
HTTPError: 403 Forbidden
```

**í•´ê²°**:
1. ì¸í„°ë„· ì—°ê²° í™•ì¸
2. í”„ë¡ì‹œ ì„¤ì • í™•ì¸
3. Hugging Face ì ‘ê·¼ ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸

---

### 3. ë¹ˆ í…ìŠ¤íŠ¸ ë°˜í™˜

**ì¦ìƒ**:
```json
{"text": "", "language": "ko"}
```

**ì›ì¸**:
- ì˜¤ë””ì˜¤ê°€ ë„ˆë¬´ ì¡°ìš©í•¨
- ë°°ê²½ ì†ŒìŒë§Œ ìˆê³  ìŒì„± ì—†ìŒ
- ìƒ˜í”Œë ˆì´íŠ¸ ë¶ˆì¼ì¹˜

**í•´ê²°**:
1. ì˜¤ë””ì˜¤ ë³¼ë¥¨ í™•ì¸
2. VAD threshold ë‚®ì¶”ê¸° (0.5 â†’ 0.3)
3. ì˜¤ë””ì˜¤ë¥¼ 16kHzë¡œ ë¦¬ìƒ˜í”Œë§

---

### 4. ì²˜ë¦¬ ì†ë„ê°€ ë„ˆë¬´ ëŠë¦¼

**ì›ì¸**:
- CPU ì„±ëŠ¥ ë¶€ì¡±
- í° ëª¨ë¸ ì‚¬ìš© (Medium/Large)

**í•´ê²°**:
1. Tiny ë˜ëŠ” Base ëª¨ë¸ë¡œ ë³€ê²½
2. GPU ì‚¬ìš© ì„¤ì •
3. ê¸´ ì˜¤ë””ì˜¤ëŠ” ì²­í‚¹ ì²˜ë¦¬

---

### 5. GPUë¥¼ ì‚¬ìš©í•˜ê³  ì‹¶ì€ë° ì¸ì‹ ì•ˆ ë¨

**í™•ì¸**:
```python
import torch
print(torch.cuda.is_available())  # Trueì—¬ì•¼ í•¨
```

**í•´ê²°**:
```bash
# CUDA ë²„ì „ í™•ì¸
nvidia-smi

# PyTorch CUDA ì¬ì„¤ì¹˜
pip uninstall torch
pip install torch --index-url https://download.pytorch.org/whl/cu118
```

---

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
my-whisper/
â”œâ”€â”€ server_stt.py           # FastAPI ì„œë²„ ë©”ì¸
â”œâ”€â”€ requirements.txt        # ì˜ì¡´ì„± ëª©ë¡
â”œâ”€â”€ README.md              # ì´ ë¬¸ì„œ
â”œâ”€â”€ .gitignore             # Git ë¬´ì‹œ íŒŒì¼
â””â”€â”€ models/                # ëª¨ë¸ ìºì‹œ (ìë™ ìƒì„±)
    â””â”€â”€ base/
```

---

## ğŸ¤ ê¸°ì—¬

ë²„ê·¸ ë¦¬í¬íŠ¸, ê¸°ëŠ¥ ì œì•ˆ, Pull Request í™˜ì˜í•©ë‹ˆë‹¤!

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

---

## ğŸ“š ì°¸ê³  ìë£Œ

### ê³µì‹ ë¬¸ì„œ
- [OpenAI Whisper](https://github.com/openai/whisper)
- [faster-whisper](https://github.com/SYSTRAN/faster-whisper)
- [CTranslate2](https://github.com/OpenNMT/CTranslate2)
- [FastAPI](https://fastapi.tiangolo.com/)

### ê´€ë ¨ í”„ë¡œì íŠ¸
- [whisper.cpp](https://github.com/ggerganov/whisper.cpp) - C++ êµ¬í˜„
- [WhisperX](https://github.com/m-bain/whisperX) - íƒ€ì„ìŠ¤íƒ¬í”„ ì •ë ¬
- [Insanely Fast Whisper](https://github.com/Vaibhavs10/insanely-fast-whisper) - ë°°ì¹˜ ìµœì í™”

---

## ğŸ“„ ë¼ì´ì„¼ìŠ¤

ì´ í”„ë¡œì íŠ¸ëŠ” MIT ë¼ì´ì„¼ìŠ¤ í•˜ì— ë°°í¬ë©ë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ [LICENSE](LICENSE) íŒŒì¼ì„ ì°¸ì¡°í•˜ì„¸ìš”.

Whisper ëª¨ë¸ ìì²´ëŠ” OpenAIì˜ ë¼ì´ì„¼ìŠ¤ë¥¼ ë”°ë¦…ë‹ˆë‹¤.

---

## ğŸ‘¤ ì‘ì„±ì

**ì¡°í™”í‰**

- GitHub: [@chopeacekr](https://github.com/chopeacekr)
- Email: chopeacekr@gmail.com

---

## ğŸ™ ê°ì‚¬ì˜ ë§

- OpenAI Whisper íŒ€
- faster-whisper ê°œë°œìë“¤
- FastAPI ì»¤ë®¤ë‹ˆí‹°

---

> ğŸ“… ìµœì¢… ì—…ë°ì´íŠ¸: 2024.11.28
> 
> ğŸ·ï¸ **íƒœê·¸**: #STT #Whisper #FastAPI #ìŒì„±ì¸ì‹ #AI